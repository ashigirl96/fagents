{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行方法\n",
    "\n",
    "```bash\n",
    "$python -m agents.scripts.train --logdir=./logdir --config=pendulum\n",
    "$python -m agents.scripts.visualize --logdir=/path/to/logdir/<time>-<config> --outdir=/path/to/outdir/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "|ファイル|内容|\n",
    "|:----|:--|\n",
    "|configs.py|タスクやアルゴリズムを特定する実験configurations|\n",
    "|networks.py|ニューラルネットワークモデル|\n",
    "|train.py|学習セットアップを含む実行可能ファイル|\n",
    "|ppo/ppo.py|PPOアルゴリズムのTensorFlowグラフ|\n",
    "\n",
    "以下の用意されたインターフェースによって、OpenAIのgymをより効率的にアルゴリズムの実装できるように統合されている。\n",
    "\n",
    "- **agents.tools.wrappers.ExternalProcess**はOpenAI Gym環境の外部プロセスの内側を構築してくれる環境ラッパー。`steps()`と`reset()`をアトリビュート(属性)アクセスとして呼べ、プロセスへおくられ結果を待つ。これはPythonのglobal interpreter lockによって制限されないでマルチ環境の実行を許す。\n",
    "- **agents.tools.BatchEnv**は複数のOpenAI Gymの環境をバッチとして捉えれるインターフェースになっている。`step()`を行動のバッチで呼ぶと、観測、報酬、情報等のバッチが与えられる。`個々の環境が外部プロセスに存在する場合、それらは並行してステップされる(??)`\n",
    "- **agents.tools.InGraphBatchEnv**はTensorFlowのグラフに統合され、`step(), reset()`がオペレーションとして作られる。現在の観測、最後の行動、報酬や端末フラグのバッチ、はtensorとして入手可能で、`tf.Variable`にsotreされる\n",
    "- **agents.tools.simulate()**は`in-graph`バッチ環境のステップと強化学習を一つのオペレーションに融合し、学習ループの内部で呼べるようにする。これにより、`tf.Session`のコールの数が減らせる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "### tools.mock_environment.py\n",
    "\n",
    "実装した。一言でいうと、まさにOpenAI Gymの型にハマった環境のモックだった。`step()`と`reset()`が用意されている。\n",
    "\n",
    "`duration`は期間という意味で、`n[duration] = n[steps] / [episode]`という感じ。勉強になったことといえば、durationが「大体これぐらいの長さ(step)だったらいいな」に対して、stepsは「実際この長さ(stepの)だった」というもの。    \n",
    "なので、モックの場合はdurations[-1]決定的で、steps[-1]は単調増加してdurations[-1]を超過すれば`done`する\n",
    "\n",
    "### tools.mock_algorithm.py\n",
    "\n",
    "実装した。`perform()`, `experience()`, `end_episode()`がなかなか意味深。なんとなくではあるけど、TensorBoardをみる限り\n",
    "\n",
    "#### 学習時\n",
    "\n",
    "<img src=\"./assets/end_episode.png\" alt=\"サンプル\" width=\"700\">\n",
    "\n",
    "<img src=\"./assets/experience.png\" alt=\"サンプル\" width=\"700\">\n",
    "\n",
    "#### 評価(eval)時\n",
    "\n",
    "<img src=\"./assets/simulate.png\" alt=\"サンプル\" width=\"500\">\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "TensorBoardの`DISTRIBUTIONS, HISTGRAM`を見るとある程度わかる。\n",
    "\n",
    "**perform**は、行動、対数確率、モード、偏差を実行し、監視してる\n",
    "\n",
    "\n",
    "いや、やっぱりよくわからん。**！！！！これらのメソッドの流れをしっかり理解する！！！！**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
